{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eebda90b-7385-496e-aa6b-0ff952a7a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b21ac0f-a969-41ba-a2d0-42e3431aeda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from biomasstry.models import UTAE\n",
    "from biomasstry.datasets import TemporalSentinel2Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb8a48e9-1fab-473c-afbe-2a823221f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de7cba2c-c36d-498c-9172-71c5b8437ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_url = \"s3://drivendata-competition-biomassters-public-us\"\n",
    "metadata_file = \"/notebooks/data/metadata_parquet/features_metadata_slim.parquet\"\n",
    "metadata_df = pd.read_parquet(metadata_file)\n",
    "chip_ids = metadata_df[metadata_df.split == \"train\"].chip_id.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69867557-6378-4a5d-b651-d68c8137ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TemporalSentinel2Dataset(chip_ids, data_url=s3_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ed4fb57-b62b-4901-817d-3efb6c9f7ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4712af23-0041-4899-a0c4-309fc7a6a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f38e3c04-0d91-4344-84d2-420b597a2e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UTAE(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11f21d75-b3c8-4d87-a8b6-3890480837ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, cid = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab902c55-de7c-4232-98f5-0fb00784c7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 10, 256, 256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c07282cc-572e-4345-b1f1-820389908d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yb = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8423041b-861a-49ac-8bc8-5a310cf7738d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 256, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ceb2bdb6-9c5c-4438-b4d5-4ec66f3a2cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = model(x[0].unsqueeze(dim=0))  # batch size of 1 to avoid kernel crashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ca142f1-c1a1-4fab-a841-961c6f608294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256, 256])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1cbd93c-94e3-4e8e-82cf-c08e373c1b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad mask: torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "pad_mask = (x == model.pad_value).all(dim=-1).all(dim=-1).all(dim=-1)\n",
    "print(f\"pad mask: {pad_mask.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab34cc45-636a-438d-aeff-f118e1d145f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: torch.Size([4, 5, 64, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "out = model.in_conv.smart_forward(x)\n",
    "print(f\"out: {out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0d32260-7b30-4a4d-99f3-2960d924a3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: torch.Size([4, 5, 64, 128, 128])\n",
      "1: torch.Size([4, 5, 64, 64, 64])\n",
      "2: torch.Size([4, 5, 128, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "feature_maps = [out]\n",
    "# SPATIAL ENCODER\n",
    "for i in range(model.n_stages - 1):\n",
    "    out = model.down_blocks[i].smart_forward(feature_maps[-1])\n",
    "    print(f\"{i}: {out.size()}\")\n",
    "    feature_maps.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0a37aea-3791-41c1-aa7f-eb5f06854309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5, 64, 256, 256])\n",
      "torch.Size([4, 5, 64, 128, 128])\n",
      "torch.Size([4, 5, 64, 64, 64])\n",
      "torch.Size([4, 5, 128, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "for f in feature_maps:\n",
    "    print(f.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a275fd1c-f698-4bcd-b97c-f4d6f2b19635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out: torch.Size([4, 128, 32, 32]), Att: torch.Size([16, 4, 5, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# TEMPORAL ENCODER\n",
    "out, att = model.temporal_encoder(\n",
    "    feature_maps[-1], batch_positions=None, pad_mask=pad_mask\n",
    ")\n",
    "print(f\"Out: {out.size()}, Att: {att.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "302191bc-8b3f-46f4-92db-7f5ab3f33165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5, 64, 64, 64])\n",
      "torch.Size([4, 5, 64, 128, 128])\n",
      "torch.Size([4, 5, 64, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for i in range(model.n_stages - 1):\n",
    "    print(feature_maps[-(i + 2)].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3943fc98-ffef-4503-adde-81ab4511d665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.return_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e12365f8-e2be-4f31-bd0c-ab3187c0ea51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fm(-2): torch.Size([4, 5, 64, 64, 64])\n",
      "skip(0): torch.Size([4, 64, 64, 64])\n",
      "out(0): torch.Size([4, 64, 64, 64])\n",
      "Fm(-3): torch.Size([4, 5, 64, 128, 128])\n",
      "skip(1): torch.Size([4, 64, 128, 128])\n",
      "out(1): torch.Size([4, 32, 128, 128])\n",
      "Fm(-4): torch.Size([4, 5, 64, 256, 256])\n",
      "skip(2): torch.Size([4, 64, 256, 256])\n",
      "out(2): torch.Size([4, 32, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# SPATIAL DECODER\n",
    "if model.return_maps:\n",
    "    maps = [out]\n",
    "for i in range(model.n_stages - 1):\n",
    "    skip = model.temporal_aggregator(\n",
    "        feature_maps[-(i + 2)], pad_mask=pad_mask, attn_mask=att\n",
    "    )\n",
    "    out = model.up_blocks[i](out, skip)\n",
    "    if model.return_maps:\n",
    "        maps.append(out)\n",
    "    print(f\"Fm({-(i + 2)}): {feature_maps[-(i + 2)].size()}\")\n",
    "    print(f\"skip({i}): {skip.size()}\")\n",
    "    print(f\"out({i}): {out.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22b89003-cc68-4c32-ac05-ce6c06d54575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out conv: torch.Size([4, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "out_c = model.out_conv(out)\n",
    "print(f\"out conv: {out_c.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a955baf9-7213-48e5-99fb-f34c9481a27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 256, 256])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
