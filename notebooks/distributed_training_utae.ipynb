{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use HuggingFace Accelerate to Train Model on Temporal (monthly) Sentinel Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator, notebook_launcher\n",
    "from accelerate.utils import set_seed\n",
    "from biomasstry.datasets import TemporalSentinel2Dataset, TemporalSentinel1Dataset\n",
    "from biomasstry.models import TemporalSentinelModel, UTAE\n",
    "from biomasstry.models.unet_tae import ConvBlock\n",
    "# from biomasstry.models.utils import run_training\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pynvml import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from transformers import TrainingArguments, Trainer, logging\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.set_start_method(\"forkserver\")\n",
    "mp.set_forkserver_preload([\"torch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu116\n",
      "11.6\n",
      "8302\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for printing GPU utilization\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 261 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(dataset: str, batch_size: int=8, num_workers: int=6):\n",
    "    \"\"\"Return train and eval DataLoaders with specified batch size.\n",
    "    \n",
    "    dataset: str\n",
    "        Dataset identifier. Must be one of \"Sentinel-1A\", \"Sentinel-1D\" or \"Sentinel-2All\"\n",
    "    batch_size: int\n",
    "        batch size for each batch.\n",
    "    \"\"\"\n",
    "    # If True, access directly S3.\n",
    "    # If False, assume data is mounted and available under '/datasets/biomassters'\n",
    "    S3_DIRECT = False\n",
    "    if S3_DIRECT:\n",
    "        data_url=\"s3://drivendata-competition-biomassters-public-us\"\n",
    "    else:\n",
    "        data_url = \"\"\n",
    "\n",
    "    if dataset == \"Sentinel-1A\": # Sentinel-1 Ascending only\n",
    "        ds = TemporalSentinel1Dataset(data_url=data_url, bands=[\"VVA\", \"VHA\"])\n",
    "    elif dataset == \"Sentinel-1D\": # Sentinel-1 Descending only\n",
    "        ds = TemporalSentinel1Dataset(data_url=data_url, bands=[\"VVD\", \"VHD\"])\n",
    "    elif dataset == \"Sentinel-1all\":\n",
    "        ds = TemporalSentinel1Dataset(data_url=data_url)\n",
    "    elif dataset == \"Sentinel-2all\":\n",
    "        ds = TemporalSentinel2Dataset(data_url=data_url)\n",
    "    else:\n",
    "        print(\"Unrecognized dataset identifier. Must be one of 'Sentinel-1A', 'Sentinel-1D' or 'Sentinel-2all'\")\n",
    "        return None, None\n",
    "\n",
    "    train_size = int(0.8*len(ds))\n",
    "    valid_size = len(ds) - train_size\n",
    "    train_set, eval_set = random_split(ds, [train_size, valid_size])\n",
    "\n",
    "    print(f\"Train samples: {len(train_set)} \"\n",
    "        f\"Val. samples: {len(eval_set)}\")\n",
    "\n",
    "    # DataLoaders\n",
    "    pin_memory = True\n",
    "    train_dataloader = DataLoader(train_set,\n",
    "                        batch_size=batch_size,\n",
    "                        num_workers=num_workers)\n",
    "    eval_dataloader = DataLoader(eval_set,\n",
    "                        batch_size=batch_size * 2,\n",
    "                        shuffle=False,\n",
    "                        pin_memory=pin_memory,\n",
    "                        num_workers=num_workers)\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False,\n",
    "                        pin_memory=pin_memory,\n",
    "                        num_workers=num_workers)\n",
    "    \n",
    "    return train_dataloader, eval_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(dataset: str,\n",
    "                  mixed_precision: str=\"fp16\",\n",
    "                  seed: int=123,\n",
    "                  batch_size: int=8,\n",
    "                  gradient_accumulation_steps: int=4,\n",
    "                  nb_epochs=2,\n",
    "                  train_mode: str=\"\"\n",
    "    ):\n",
    "    \"\"\"Main Training and Evaluation Loop to be called by accelerator.notebook_launcher().\"\"\"\n",
    "    print(f\"Args: {mixed_precision}, {seed}, {batch_size}, \"\n",
    "          f\"{gradient_accumulation_steps}, {nb_epochs}, {train_mode}\")\n",
    "\n",
    "    # Set random seed\n",
    "    set_seed(seed)\n",
    "\n",
    "    # Initialize Accelerator\n",
    "    accelerator = Accelerator(mixed_precision=mixed_precision,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps)\n",
    "\n",
    "    # Build DataLoaders\n",
    "    train_dataloader, eval_dataloader = get_dataloaders(dataset, batch_size=batch_size)\n",
    "\n",
    "    # Assign model inputs based on dataset\n",
    "    if dataset == \"Sentinel-1A\":\n",
    "        input_nc = 2\n",
    "        n_tsamples = 6\n",
    "    elif dataset == \"Sentinel-1D\":\n",
    "        input_nc = 2\n",
    "        n_tsamples = 6\n",
    "    elif dataset == \"Sentinel-1all\":\n",
    "        input_nc = 4\n",
    "        n_tsamples = 6\n",
    "    else:\n",
    "    # Create model\n",
    "    if train_mode == \"tune\":\n",
    "        print(f\"Fine tuning pre-trained weights\")\n",
    "        print(f\"Loading weights from {pretrained_weights_path}\")\n",
    "        saved_dict = torch.load(pretrained_weights_path)\n",
    "        model = UTAE(10, out_conv=[32, 20])  # Initialize the original model & load pre-trained weights\n",
    "        model.load_state_dict(saved_dict[\"state_dict\"], )\n",
    "        model.out_conv = ConvBlock([32, 32, 1], padding_mode=\"reflect\")  # Modify the last layer\n",
    "        lr = 0.001\n",
    "        print(\"Pre-trained weights loaded successfully.\")\n",
    "    else:\n",
    "        model = UTAE(input_nc)  # modify output layer to predict AGBM\n",
    "        lr = 0.02\n",
    "        if train_mode == \"resume\":\n",
    "            print(\"Resuming training...\")\n",
    "            print(f\"Loading model from {saved_state_path}\")\n",
    "            state_dict = torch.load(saved_state_path)  # , map_location=accelerator.device)\n",
    "            model.load_state_dict(state_dict)\n",
    "            print(f\"Model loaded successfully.\")\n",
    "\n",
    "    loss_function = nn.MSELoss(reduction='mean')  # Loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  # Optimizer\n",
    "    \n",
    "    \n",
    "    # model = UTAE(input_nc)\n",
    "    for i in tqdm(range(nb_epochs), disable=not accelerator.is_local_main_process):\n",
    "        accelerator.print(f\"Epoch {i+1}\")\n",
    "        epoch_start = time()\n",
    "        for b, batch in enumerate(tqdm(train_dataloader, disable=not accelerator.is_local_main_process)):\n",
    "            inputs, targets, chip_id = batch\n",
    "            with accelerator.accumulate(model):\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, targets)\n",
    "                accelerator.backward(loss)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "        epoch_end = time()\n",
    "        accelerator.print(f\"  Training time: {epoch_end - epoch_start}\")\n",
    "        \n",
    "        # Save Model State Dict after each epoch in order to continue training later\n",
    "        unwrap_model = accelerator.unwrap_model(model)  # Unwrap the Accelerator model\n",
    "        train_model_path = save_path[:-3] + f\"_E{i+16}.pt\"\n",
    "        accelerator.save(unwrap_model.state_dict(), train_model_path)\n",
    "        accelerator.print(f\"  Model file path: {train_model_path}\")\n",
    "\n",
    "        # Validation Loop\n",
    "        val_loss = 0.0\n",
    "        num_elements = 0\n",
    "        for batch in tqdm(eval_dataloader, disable=not accelerator.is_local_main_process):\n",
    "            inputs, targets, _ = batch\n",
    "            with torch.no_grad():\n",
    "                predictions = model(inputs)\n",
    "                print(f\"Batch {b+1}. Chip ID: {chip_id}. Input size: {inputs.size()}. Output size: {targets.size()}.\")\n",
    "                \n",
    "        epoch_end = time()\n",
    "        accelerator.print(f\"  Training time: {epoch_end - epoch_start}\")\n",
    "        \n",
    "        # Save Model State Dict after each epoch in order to continue training later\n",
    "        unwrap_model = accelerator.unwrap_model(model)  # Unwrap the Accelerator model\n",
    "        train_model_path = save_path[:-3] + f\"_E{i+1}.pt\"\n",
    "        accelerator.save(unwrap_model.state_dict(), train_model_path)\n",
    "        accelerator.print(f\"  Model file path: {train_model_path}\")\n",
    "\n",
    "        # Validation Loop\n",
    "        val_loss = 0.0\n",
    "        num_elements = 0\n",
    "        for batch in tqdm(eval_dataloader, disable=not accelerator.is_local_main_process):\n",
    "            inputs, targets, _ = batch\n",
    "            with torch.no_grad():\n",
    "                predictions = model(inputs)\n",
    "            # Gather all predictions and targets\n",
    "            all_predictions, all_targets = accelerator.gather_for_metrics((predictions, targets))\n",
    "            num_elements += all_predictions.shape[0]\n",
    "            val_loss += loss_function(all_predictions, all_targets).item()\n",
    "\n",
    "        val_loss /= num_elements\n",
    "        val_rmse = np.round(np.sqrt(val_loss), 5)\n",
    "        accelerator.print(f\"  Validation RMSE: {val_rmse:>8f}\")\n",
    "        # check validation score, if improved then save model\n",
    "        if min_valid_metric > val_rmse:\n",
    "            accelerator.print(f\"  Validation RMSE Decreased({min_valid_metric:.6f}--->{val_rmse:.6f})\")\n",
    "            min_valid_metric = val_rmse\n",
    "\n",
    "            # Saving Model State Dict\n",
    "            unwrap_model = accelerator.unwrap_model(model)  # Unwrap the Accelerator model\n",
    "            accelerator.save(unwrap_model.state_dict(), best_model_path)\n",
    "            accelerator.print(f\"  Best Model file path: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<<<<<<< local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on one GPU.\n",
      "Args: fp16, 123, 8, 4, 15, resume\n",
      "Train samples: 6951 Val. samples: 1738\n",
      "Resuming training...\n",
      "Loading model from /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_tune_E5.pt\n",
      "Model loaded successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8113fb5d5e244fc4bf90cf55d1a7ceea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/artifacts/pretrained_utae/f1model.pth.tar /notebooks/artifacts/20230126_UTAE_Sentinel-1all_B32_E15.pt /notebooks/artifacts/20230127_UTAE_Sentinel-1all_B32_resume.pt /notebooks/artifacts/20230127_UTAE_Sentinel-1all_B32_resume_BEST.pt\n",
      "Launching training on one GPU.\n",
      "Args: fp16, 123, 8, 4, 5, resume\n",
      "Train samples: 6951 Val. samples: 1738\n",
      "Resuming training...\n",
      "Loading model from /notebooks/artifacts/20230126_UTAE_Sentinel-1all_B32_E15.pt\n",
      "Model loaded successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06dd9c4842f74c70be0b6258ddd91a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>>>>> remote\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98daf3dc64542768b96ab1e306df1a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<<<<<<< local\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1709ba18f8ed43c1b70a27202658dbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training time: 970.5138721466064\n",
      "  Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_E6.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a38c7c6152476089e807f3f8f3c733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation RMSE: 22.675860\n",
      "  Validation RMSE Decreased(inf--->22.675860)\n",
      "  Best Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_BEST.pt\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b530cfaed644b1ea777dece9ceb61bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training time: 850.9564437866211\n",
      "  Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_E7.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131e95dcbdc54264b29aa15bb795637f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation RMSE: 21.989560\n",
      "  Validation RMSE Decreased(22.675860--->21.989560)\n",
      "  Best Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_BEST.pt\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8713f8a1f819436488c7cb135f94988a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training time: 871.3295848369598\n",
      "  Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_E8.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137a05d2332747c5b5317d1af9f1c106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation RMSE: 21.342640\n",
      "  Validation RMSE Decreased(21.989560--->21.342640)\n",
      "  Best Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_BEST.pt\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b96e9d67e44ca6ba3b3867d5cc8bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training time: 868.7869493961334\n",
      "  Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_E9.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068a134ecc124936a8b48205db121be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation RMSE: 20.668860\n",
      "  Validation RMSE Decreased(21.342640--->20.668860)\n",
      "  Best Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_BEST.pt\n",
      "Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62d64b9467d4883963056f416e3ae25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training time: 846.2696478366852\n",
      "  Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_E10.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9d73b7c26147e09f03cd10a7a0cb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation RMSE: 20.031980\n",
      "  Validation RMSE Decreased(20.668860--->20.031980)\n",
      "  Best Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_BEST.pt\n",
      "Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28074aa886dc4bf8b916871c4cb34863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training time: 875.7249212265015\n",
      "  Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_E11.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b532fc9dd5749fabb3d0131db850abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation RMSE: 19.420370\n",
      "  Validation RMSE Decreased(20.031980--->19.420370)\n",
      "  Best Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_BEST.pt\n",
      "Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329f96db86304e11a26bc0978f35284b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training time: 873.7554521560669\n",
      "  Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_E12.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389d206849cc4908b18ada56ab67b82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation RMSE: 18.784620\n",
      "  Validation RMSE Decreased(19.420370--->18.784620)\n",
      "  Best Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_BEST.pt\n",
      "Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec4089aa52148c2abc1c897c6582d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training time: 850.6407158374786\n",
      "  Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_E13.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223c61e6ceeb4cf0923e2766c23baeb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation RMSE: 18.220880\n",
      "  Validation RMSE Decreased(18.784620--->18.220880)\n",
      "  Best Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_BEST.pt\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246f15b971d44a4a873f28f90f7fa571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training time: 849.4932560920715\n",
      "  Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_E14.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc49aa7c20bd4430aabf998075d8e46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation RMSE: 17.630090\n",
      "  Validation RMSE Decreased(18.220880--->17.630090)\n",
      "  Best Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_BEST.pt\n",
      "Epoch 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e28d05cf9a4436acdcb59996cd3e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training time: 900.840512752533\n",
      "  Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_E15.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d38df09249b402c858b95edc3b72971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation RMSE: 17.053880\n",
      "  Validation RMSE Decreased(17.630090--->17.053880)\n",
      "  Best Model file path: /notebooks/artifacts/20230118_UTAE_Sentinel-2all_B32_resume_BEST.pt\n",
      "Epoch 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc8218ca2a447748554e694eeba8608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=======\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282fd0f67c964763a49dbadbb25476a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training time: 1188.8308675289154\n",
      "  Model file path: /notebooks/artifacts/20230127_UTAE_Sentinel-1all_B32_resume_E16.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b09386f0352482fa46311c85e414075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation RMSE: 11.215710\n",
      "  Validation RMSE Decreased(inf--->11.215710)\n",
      "  Best Model file path: /notebooks/artifacts/20230127_UTAE_Sentinel-1all_B32_resume_BEST.pt\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034fa23a07da4976b1722a6821d1d0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training time: 1074.6486003398895\n",
      "  Model file path: /notebooks/artifacts/20230127_UTAE_Sentinel-1all_B32_resume_E17.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3574998b38b452c983555d63e56cb1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation RMSE:      nan\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecb75d266d04949979c864cb94c73e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training time: 1083.8182561397552\n",
      "  Model file path: /notebooks/artifacts/20230127_UTAE_Sentinel-1all_B32_resume_E18.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1094d565b040423e828a79a1825f1976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation RMSE:      nan\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cca1cf5299b4e67bab40f603d06065d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training time: 1084.0863275527954\n",
      "  Model file path: /notebooks/artifacts/20230127_UTAE_Sentinel-1all_B32_resume_E19.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb9508d79e146b59ad3c965f5879ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation RMSE:      nan\n",
      "Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de52f96bcff4cab9733833b28740f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(pretrained_weights_path, saved_state_path, save_path, best_model_path)\n\u001b[1;32m     21\u001b[0m train_args \u001b[38;5;241m=\u001b[39m (dataset, mixed_precision, seed, batch_size, gradient_accumulation_steps, nb_epochs, train_mode)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mnotebook_launcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_loop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/accelerate/launchers.py:135\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, use_fp16, mixed_precision, use_port)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLaunching training on CPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m patch_environment(use_mps_device\u001b[38;5;241m=\u001b[39muse_mps_device):\n\u001b[0;32m--> 135\u001b[0m     \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(dataset, mixed_precision, seed, batch_size, gradient_accumulation_steps, nb_epochs, train_mode)\u001b[0m\n\u001b[1;32m     69\u001b[0m accelerator\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m epoch_start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_dataloader, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m accelerator\u001b[38;5;241m.\u001b[39mis_local_main_process)):\n\u001b[1;32m     72\u001b[0m     inputs, targets, chip_id \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m accelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tqdm/notebook.py:258\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/accelerate/data_loader.py:382\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m current_batch\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/accelerate/utils/operations.py:131\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_has_to_method\u001b[39m(t):\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_send_to_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_has_to_method\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/accelerate/utils/operations.py:80\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03mRecursively apply a function on a data structure that is a nested list/tuple/dictionary of a given base type.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    The same data structure as `data` with `func` applied to every object of type `main_type`.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhonor_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m     91\u001b[0m         {\n\u001b[1;32m     92\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m         }\n\u001b[1;32m     97\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/accelerate/utils/operations.py:51\u001b[0m, in \u001b[0;36mhonor_type\u001b[0;34m(obj, generator)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03mCast a generator to the same type as obj (list, tuple or namedtuple)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# Some objects may not be able to instantiate from a generator directly\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(generator))\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/accelerate/utils/operations.py:83\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03mRecursively apply a function on a data structure that is a nested list/tuple/dictionary of a given base type.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    The same data structure as `data` with `func` applied to every object of type `main_type`.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m honor_type(\n\u001b[1;32m     81\u001b[0m         data,\n\u001b[1;32m     82\u001b[0m         (\n\u001b[0;32m---> 83\u001b[0m             \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m data\n\u001b[1;32m     87\u001b[0m         ),\n\u001b[1;32m     88\u001b[0m     )\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m     91\u001b[0m         {\n\u001b[1;32m     92\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m         }\n\u001b[1;32m     97\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/accelerate/utils/operations.py:99\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m     91\u001b[0m         {\n\u001b[1;32m     92\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m         }\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_on_other_type:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt apply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on object of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, only of nested list/tuple/dicts of objects \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat satisfy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/accelerate/utils/operations.py:124\u001b[0m, in \u001b[0;36msend_to_device.<locals>._send_to_device\u001b[0;34m(t, device, non_blocking)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_send_to_device\u001b[39m(t, device, non_blocking):\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 124\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>>>>> remote\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1. Chip ID: ['fd839d71', 'a3aac2ce', 'e7325413', '2409a7cf']. Input size: torch.Size([4, 5, 10, 256, 256]). Output size: torch.Size([4, 1, 256, 256]).\n",
      "Batch 11. Chip ID: ['fe7f68eb', '2f5131c6', '57039896', 'dc8dc18d']. Input size: torch.Size([4, 5, 10, 256, 256]). Output size: torch.Size([4, 1, 256, 256]).\n",
      "Batch 21. Chip ID: ['b3c29fad', 'e935c106', '4e54622e', 'a759e918']. Input size: torch.Size([4, 5, 10, 256, 256]). Output size: torch.Size([4, 1, 256, 256]).\n",
      "Batch 31. Chip ID: ['0c1b5ede', '1925f7d8', '52d4b426', 'd4475d0a']. Input size: torch.Size([4, 5, 10, 256, 256]). Output size: torch.Size([4, 1, 256, 256]).\n",
      "Batch 41. Chip ID: ['2b835255', 'b4d9dfcc', '8c94e3ad', '671cc3e6']. Input size: torch.Size([4, 5, 10, 256, 256]). Output size: torch.Size([4, 1, 256, 256]).\n",
      "Batch 51. Chip ID: ['ce9d0a64', 'c0d5cc9c', 'd4061b6d', '3ff95cac']. Input size: torch.Size([4, 5, 10, 256, 256]). Output size: torch.Size([4, 1, 256, 256]).\n",
      "Batch 61. Chip ID: ['35cb0400', '88af4eb2', '56ac3ec6', 'f7fcd82b']. Input size: torch.Size([4, 5, 10, 256, 256]). Output size: torch.Size([4, 1, 256, 256]).\n",
      "Batch 71. Chip ID: ['cb13eaf5', '8588f3b8', '8d35b812', 'e3906078']. Input size: torch.Size([4, 5, 10, 256, 256]). Output size: torch.Size([4, 1, 256, 256]).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Notebook Launcher for distributed training\u001b[39;00m\n\u001b[1;32m     20\u001b[0m train_args \u001b[38;5;241m=\u001b[39m (dataset, mixed_precision, seed, batch_size, gradient_accumulation_steps, nb_epochs)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mnotebook_launcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_loop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/accelerate/launchers.py:135\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, use_fp16, mixed_precision, use_port)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLaunching training on CPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m patch_environment(use_mps_device\u001b[38;5;241m=\u001b[39muse_mps_device):\n\u001b[0;32m--> 135\u001b[0m     \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(dataset, mixed_precision, seed, batch_size, gradient_accumulation_steps, nb_epochs, train_mode)\u001b[0m\n\u001b[1;32m     66\u001b[0m accelerator\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m epoch_start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_dataloader, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m accelerator\u001b[38;5;241m.\u001b[39mis_local_main_process)):\n\u001b[1;32m     69\u001b[0m     inputs, targets, chip_id \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# with accelerator.accumulate(model):\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m#     outputs = model(inputs)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m#     loss = loss_function(outputs, targets)\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m#     accelerator.backward(loss)\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m#     optimizer.step()\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m#     optimizer.zero_grad()\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tqdm/notebook.py:258\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/accelerate/data_loader.py:383\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m send_to_device(current_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 383\u001b[0m next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m current_batch\n\u001b[1;32m    385\u001b[0m current_batch \u001b[38;5;241m=\u001b[39m next_batch\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataset.py:290\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/notebooks/src/biomasstry/datasets/temporal_sentinel2.py:188\u001b[0m, in \u001b[0;36mTemporalSentinel2Dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    185\u001b[0m img_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_image_paths(chip_id)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# Create temporal tensor of size TxCxWxH\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m timg_data \u001b[38;5;241m=\u001b[39m \u001b[43mmake_temporal_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mband_indexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# clip Sentinel-2 to [0, 10000]\u001b[39;00m\n\u001b[1;32m    191\u001b[0m timg_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclip(timg_data, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n",
      "File \u001b[0;32m/notebooks/src/biomasstry/datasets/utils.py:42\u001b[0m, in \u001b[0;36mmake_temporal_tensor\u001b[0;34m(image_paths, band_indexes)\u001b[0m\n\u001b[1;32m     40\u001b[0m im1 \u001b[38;5;241m=\u001b[39m load_raster(image_paths[\u001b[38;5;241m1\u001b[39m], indexes\u001b[38;5;241m=\u001b[39mband_indexes\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m     41\u001b[0m im2 \u001b[38;5;241m=\u001b[39m load_raster(image_paths[\u001b[38;5;241m2\u001b[39m], indexes\u001b[38;5;241m=\u001b[39mband_indexes\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m---> 42\u001b[0m im3 \u001b[38;5;241m=\u001b[39m \u001b[43mload_raster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mband_indexes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m im4 \u001b[38;5;241m=\u001b[39m load_raster(image_paths[\u001b[38;5;241m4\u001b[39m], indexes\u001b[38;5;241m=\u001b[39mband_indexes\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# return torch.stack([load_raster(img_path, indexes=band_indexes.tolist()) \u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#                          for img_path in image_paths], dim=0)\u001b[39;00m\n",
      "File \u001b[0;32m/notebooks/src/biomasstry/datasets/utils.py:28\u001b[0m, in \u001b[0;36mload_raster\u001b[0;34m(file_url, indexes)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Save bytes to array\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m MemoryFile(raw_bytes) \u001b[38;5;28;01mas\u001b[39;00m memfile:\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmemfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m buffer:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m indexes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m             array \u001b[38;5;241m=\u001b[39m buffer\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/rasterio/env.py:394\u001b[0m, in \u001b[0;36mensure_env.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Env\u001b[38;5;241m.\u001b[39mfrom_defaults():\n\u001b[0;32m--> 394\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/rasterio/io.py:138\u001b[0m, in \u001b[0;36mMemoryFile.open\u001b[0;34m(self, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    137\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVSI path: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(mempath\u001b[38;5;241m.\u001b[39mpath))\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDatasetReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmempath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     writer \u001b[38;5;241m=\u001b[39m get_writer_for_driver(driver)\n",
      "File \u001b[0;32mrasterio/_base.pyx:311\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/rasterio/_path.py:113\u001b[0m, in \u001b[0;36m_UnparsedPath.name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m\"\"\"Encapsulates legacy GDAL filenames\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03mAttributes\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    The legacy GDAL filename.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m path \u001b[38;5;241m=\u001b[39m attr\u001b[38;5;241m.\u001b[39mib()\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mname\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;124;03m\"\"\"The unparsed path's original path\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = \"Sentinel-1all\"\n",
    "mixed_precision = \"fp16\"\n",
    "seed = 123\n",
    "batch_size = 8\n",
    "gradient_accumulation_steps = 4\n",
    "nb_epochs = 5\n",
    "train_mode = \"resume\"\n",
    "\n",
    "artifacts_dir = \"/notebooks/artifacts\"\n",
    "model_name = \"UTAE\"\n",
    "date = \"20230127\"\n",
    "pretrained_weights_path = artifacts_dir + \"/pretrained_utae/f1model.pth.tar\"  # for fine tuning\n",
    "saved_state_path = artifacts_dir + \"/20230126_UTAE_Sentinel-1all_B32_E15.pt\"  # for resuming training\n",
    "\n",
    "save_path = artifacts_dir + (f\"/{date}_{model_name}_{dataset}_B\"\n",
    "        f\"{batch_size * gradient_accumulation_steps}_{train_mode}.pt\")\n",
    "best_model_path = save_path[:-3] + \"_BEST.pt\"\n",
    "\n",
    "# Notebook Launcher for distributed training\n",
    "print(pretrained_weights_path, saved_state_path, save_path, best_model_path)\n",
    "train_args = (dataset, mixed_precision, seed, batch_size, gradient_accumulation_steps, nb_epochs, train_mode)\n",
    "notebook_launcher(training_loop, train_args, num_processes=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Save the metrics to a file\n",
    "train_metrics_zipped = list(zip(np.arange(0, len(train_metrics)), train_metrics))\n",
    "metrics = {'training': train_metrics_zipped, 'validation': val_metrics}\n",
    "train_metrics_df = pd.DataFrame(metrics['training'], columns=[\"step\", \"score\"])\n",
    "val_metrics_df = pd.DataFrame(metrics[\"validation\"], columns=[\"step\", \"score\"])\n",
    "train_metrics_df.to_csv(artifacts_dir + \"/train_metrics.csv\")\n",
    "val_metrics_df.to_csv(artifacts_dir + \"/val_metrics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
