{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use HuggingFace Accelerate to Train Model on Temporal (monthly) Sentinel Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator, notebook_launcher\n",
    "from accelerate.utils import set_seed\n",
    "from biomasstry.datasets import TemporalSentinel2Dataset, TemporalSentinel1Dataset\n",
    "from biomasstry.models import TemporalSentinelModel, UTAE\n",
    "# from biomasstry.models.utils import run_training\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pynvml import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from transformers import TrainingArguments, Trainer, logging\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for printing GPU utilization\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 261 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(dataset: str, batch_size: int=16, num_workers: int=6):\n",
    "    \"\"\"Return train and eval DataLoaders with specified batch size.\n",
    "    \n",
    "    dataset: str\n",
    "        Dataset identifier. Must be one of \"Sentinel-1A\", \"Sentinel-1D\" or \"Sentinel-2All\"\n",
    "    batch_size: int\n",
    "        batch size for each batch.\n",
    "    \"\"\"\n",
    "    # If True, access directly S3.\n",
    "    # If False, assume data is mounted and available under '/datasets/biomassters'\n",
    "    S3_DIRECT = False\n",
    "    if S3_DIRECT:\n",
    "        data_url=\"s3://drivendata-competition-biomassters-public-us\"\n",
    "    else:\n",
    "        data_url = \"\"\n",
    "\n",
    "    random_perm = np.random.permutation(len(chip_ids))\n",
    "    cut = int(0.8 * len(chip_ids))\n",
    "    train_split = random_perm[:cut]\n",
    "    eval_split = random_perm[:cut]\n",
    "\n",
    "    if dataset == \"Sentinel-1A\": # Sentinel-1 Ascending only\n",
    "        ds = TemporalSentinel1Dataset(data_url=data_url, bands=[\"VVA\", \"VHA\"])\n",
    "    elif dataset == \"Sentinel-1D\": # Sentinel-1 Descending only\n",
    "        ds = TemporalSentinel1Dataset(data_url=data_url, bands=[\"VVD\", \"VHD\"])\n",
    "    elif dataset == \"Sentinel-2all\":\n",
    "        train_ds = TemporalSentinel2Dataset(train_split, data_url=data_url)\n",
    "        eval_ds = TemporalSentinel2Dataset(eval_split, data_url=data_url)\n",
    "    else:\n",
    "        print(\"Unrecognized dataset identifier. Must be one of 'Sentinel-1A', 'Sentinel-1D' or 'Sentinel-2all'\")\n",
    "        return None, None\n",
    "\n",
    "    train_size = int(0.8*len(ds))\n",
    "    valid_size = len(ds) - train_size\n",
    "    train_set, val_set = random_split(ds, [train_size, valid_size])\n",
    "    print(f\"Train samples: {len(train_set)} \"\n",
    "        f\"Val. samples: {len(val_set)}\")\n",
    "\n",
    "    # DataLoaders\n",
    "    train_dataloader = DataLoader(train_ds,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        pin_memory=True,\n",
    "                        num_workers=num_workers)\n",
    "    eval_dataloader = DataLoader(eval_ds,\n",
    "                        batch_size=batch_size * 2,\n",
    "                        shuffle=False,\n",
    "                        pin_memory=True,\n",
    "                        num_workers=num_workers)\n",
    "    return train_dataloader, eval_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(dataset: str,\n",
    "    mixed_precision: str=\"fp16\",\n",
    "    seed: int=123,\n",
    "    batch_size: int=16,\n",
    "    gradient_accumulation_steps: int=4,\n",
    "    nb_epochs=2):\n",
    "    \"\"\"Main Training and Evaluation Loop to be called by accelerator.notebook_launcher().\"\"\"\n",
    "    # Set random seed\n",
    "    set_seed(seed)\n",
    "\n",
    "    # Initialize Accelerator\n",
    "    accelerator = Accelerator(mixed_precision=mixed_precision,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps)\n",
    "\n",
    "    # Build DataLoaders\n",
    "    train_dataloader, eval_dataloader = get_dataloaders(dataset, batch_size=batch_size)\n",
    "\n",
    "    # Assign model inputs based on dataset\n",
    "    if dataset == \"Sentinel-1A\":\n",
    "        input_nc = 2\n",
    "        n_tsamples = 6\n",
    "    elif dataset == \"Sentinel-1D\":\n",
    "        input_nc = 2\n",
    "        n_tsamples = 6\n",
    "    else:\n",
    "        input_nc = 10\n",
    "        n_tsamples = 5\n",
    "    # Create model\n",
    "    model = UTAE(input_nc)\n",
    "\n",
    "    loss_function = nn.MSELoss(reduction='mean')  # Loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.02)  # Optimizer\n",
    "    \n",
    "    # Prepare everything to use accelerator\n",
    "    # Maintain order while unpacking\n",
    "    model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(model,\n",
    "                                                                optimizer,\n",
    "                                                                train_dataloader,\n",
    "                                                                eval_dataloader)\n",
    "    min_valid_metric = np.inf\n",
    "    save_path = artifacts_dir + (f\"/{date}_{model_name}_{dataset}_B\"\n",
    "        f\"{batch_size * gradient_accumulation_steps}.pt\")\n",
    "    \n",
    "    # Training loop\n",
    "    for i in tqdm(range(nb_epochs)):\n",
    "        accelerator.print(f\"Epoch {i+1}\")\n",
    "        epoch_start = time()\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            inputs = batch[\"image\"]\n",
    "            targets = batch[\"target\"]\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_end = time()\n",
    "        accelerator.print(f\"  Training time: {epoch_end - epoch_start}\")\n",
    "        \n",
    "        # Save Model State Dict after each epoch in order to continue training later\n",
    "        unwrap_model = accelerator.unwrap_model(model)  # Unwrap the Accelerator model\n",
    "        accelerator.save(unwrap_model.state_dict(), save_path[:-3] + \"_E{i+1}.pt\")\n",
    "        accelerator.print(f\"  Model file path: {save_path}\")\n",
    "        \n",
    "        # Validation Loop\n",
    "        val_loss = 0.0\n",
    "        num_elements = 0\n",
    "        for batch in tqdm(eval_dataloader):\n",
    "            inputs = batch[\"image\"]\n",
    "            targets = batch[\"target\"]\n",
    "            with torch.no_grad():\n",
    "                predictions = model(inputs)\n",
    "            # Gather all predictions and targets\n",
    "            all_predictions, all_targets = accelerator.gather_for_metrics((predictions, targets))\n",
    "            num_elements += all_predictions.shape[0]\n",
    "            val_loss += loss_function(all_predictions, all_targets).item()\n",
    "\n",
    "        val_loss /= num_elements\n",
    "        val_rmse = np.round(np.sqrt(val_loss), 5)\n",
    "        accelerator.print(f\"  Validation RMSE: {val_rmse:>8f}\")\n",
    "        # check validation score, if improved then save model\n",
    "        if min_valid_metric > val_rmse:\n",
    "            accelerator.print(f\"  Validation RMSE Decreased({min_valid_metric:.6f}--->{val_rmse:.6f})\")\n",
    "            min_valid_metric = val_rmse\n",
    "\n",
    "            # Saving Model State Dict\n",
    "            unwrap_model = accelerator.unwrap_model(model)  # Unwrap the Accelerator model\n",
    "            accelerator.save(unwrap_model.state_dict(), save_path[:-3] + \"_BEST.pt\")\n",
    "            accelerator.print(f\"  Best Model file path: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fnames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m metadata_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(metadata_file)\n\u001b[1;32m     14\u001b[0m chip_ids \u001b[38;5;241m=\u001b[39m metadata_df[metadata_df\u001b[38;5;241m.\u001b[39msplit \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mchip_id\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m---> 16\u001b[0m random_perm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(\u001b[38;5;28mlen\u001b[39m(\u001b[43mfnames\u001b[49m))\n\u001b[1;32m     17\u001b[0m cut \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(fnames))\n\u001b[1;32m     18\u001b[0m train_split \u001b[38;5;241m=\u001b[39m random_perm[:cut]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fnames' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = \"Sentinel-2all\"\n",
    "mixed_precision = \"fp16\",\n",
    "seed =123,\n",
    "batch_size =16,\n",
    "gradient_accumulation_steps =4,\n",
    "nb_epochs=2\n",
    "\n",
    "artifacts_dir = \"/notebooks/artifacts\"\n",
    "model_name = \"UTAE\"\n",
    "date = \"20230117\"\n",
    "\n",
    "metadata_file = \"/notebooks/data/metadata_parquet/features_metadata_slim.parquet\"\n",
    "metadata_df = pd.read_parquet(metadata_file)\n",
    "chip_ids = metadata_df[metadata_df.split == \"train\"].chip_id.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Launcher for distributed training\n",
    "train_args = (dataset, mixed_precision, seed, batch_size, gradient_accumulation_steps, nb_epochs)\n",
    "notebook_launcher(training_loop, train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### Save the metrics to a file\n",
    "train_metrics_zipped = list(zip(np.arange(0, len(train_metrics)), train_metrics))\n",
    "metrics = {'training': train_metrics_zipped, 'validation': val_metrics}\n",
    "train_metrics_df = pd.DataFrame(metrics['training'], columns=[\"step\", \"score\"])\n",
    "val_metrics_df = pd.DataFrame(metrics[\"validation\"], columns=[\"step\", \"score\"])\n",
    "train_metrics_df.to_csv(artifacts_dir + \"/train_metrics.csv\")\n",
    "val_metrics_df.to_csv(artifacts_dir + \"/val_metrics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
