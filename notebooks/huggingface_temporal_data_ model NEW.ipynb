{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use HuggingFace Accelerate to Train Model on Temporal (monthly) Sentinel Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from biomasstry.datasets import TemporalSentinel2Dataset, TemporalSentinel1Dataset\n",
    "from biomasstry.models import TemporalSentinelModel, UTAE\n",
    "# from biomasstry.models.utils import run_training\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pynvml import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from transformers import TrainingArguments, Trainer, logging\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for printing GPU utilization\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 261 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_DIRECT = False  # Access S3 directly or as a mounted data source\n",
    "if S3_DIRECT:\n",
    "    data_url=\"s3://drivendata-competition-biomassters-public-us\"\n",
    "else:\n",
    "    data_url = \"\"\n",
    "\n",
    "datasets = [\"Sentinel-1A\",  # Sentinel-1 Ascending only\n",
    "            \"Sentinel-1D\",  # Sentinel-1 Descending only\n",
    "            \"Sentinel-2all\"]\n",
    "\n",
    "dataset = datasets[2]\n",
    "if dataset == \"Sentinel-1A\":\n",
    "    ds = TemporalSentinel1Dataset(data_url=data_url, bands=[\"VVA\", \"VHA\"])\n",
    "    input_nc = 2\n",
    "    n_tsamples = 6\n",
    "elif dataset == \"Sentinel-1A\":\n",
    "    ds = TemporalSentinel1Dataset(data_url=data_url, bands=[\"VVD\", \"VHD\"])\n",
    "    input_nc = 2\n",
    "    n_tsamples = 6\n",
    "elif dataset == \"Sentinel-2all\":\n",
    "    ds = TemporalSentinel2Dataset(data_url=data_url)\n",
    "    input_nc = 10\n",
    "    n_tsamples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 800 Val. samples: 200\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "train_size = int(0.8*len(ds))\n",
    "valid_size = len(ds) - train_size\n",
    "train_set, val_set = random_split(ds, [train_size, valid_size])\n",
    "print(f\"Train samples: {len(train_set)} \"\n",
    "      f\"Val. samples: {len(val_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TemporalSentinelModel(\n",
    "#     n_tsamples=n_tsamples, \n",
    "#     input_nc=input_nc,\n",
    "#     output_nc=1,\n",
    "# )  # .to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UTAE(input_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss(reduction='mean')  # .to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = {\n",
    "    \"output_dir\": \"/notebooks/artifacts\",\n",
    "    \"overwrite_output_dir\": \"True\",\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"num_train_epochs\": 10,\n",
    "    \"log_level\": \"error\",\n",
    "    \"report_to\": \"none\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    **default_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "num_workers = 4\n",
    "train_dataloader = DataLoader(train_set,\n",
    "                      batch_size=training_args.per_device_train_batch_size,\n",
    "                      shuffle=True,\n",
    "                      pin_memory=True,\n",
    "                      num_workers=num_workers)\n",
    "eval_dataloader = DataLoader(val_set,\n",
    "                    batch_size=training_args.per_device_train_batch_size,\n",
    "                    shuffle=False,\n",
    "                    pin_memory=True,\n",
    "                    num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Trainer(model, args=training_args, train_dataset=train_set)\n",
    "\n",
    "# HuggingFace Accelerator with Gradient Accumulation\n",
    "accelerator = Accelerator(gradient_accumulation_steps=4, mixed_precision='fp16')\n",
    "\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(model,\n",
    "                                                                optimizer,\n",
    "                                                                train_dataloader,\n",
    "                                                                eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file path: /notebooks/artifacts/20230116_UTAE_Sentinel-2all_B32_E10.pt\n"
     ]
    }
   ],
   "source": [
    "artifacts_dir = \"/notebooks/artifacts\"\n",
    "model_name = \"UTAE\"\n",
    "nb_epochs = 10\n",
    "date = \"20230116\"\n",
    "save_path = artifacts_dir + (f\"/{date}_{model_name}_{dataset}_B\"\n",
    "    f\"{training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\"\n",
    "    f\"_E{nb_epochs}.pt\")\n",
    "print(f\"Model file path: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3fb3d403ef64ecba248911677427066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2cbb0f43d5442d8f1b5b8065d0fc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch training time: 53.856507539749146\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bac2bafc25c4325955b44f77f250f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Error: \n",
      " RMSE:      nan \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af99c03c3c748208e3f482786656488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch training time: 50.389044761657715\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db4ebc500a140bfb50e4d6a34ed2364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Error: \n",
      " RMSE:      nan \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d588f7d997b04918afcaef0c5fda251e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, targets)\n\u001b[1;32m     24\u001b[0m     accelerator\u001b[38;5;241m.\u001b[39mbackward(loss)\n\u001b[0;32m---> 25\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     train_metrics_epoch\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mround(np\u001b[38;5;241m.\u001b[39msqrt(loss\u001b[38;5;241m.\u001b[39mitem()), \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m     28\u001b[0m epoch_end \u001b[38;5;241m=\u001b[39m time()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/accelerate/optimizer.py:133\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    131\u001b[0m     xm\u001b[38;5;241m.\u001b[39moptimizer_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, optimizer_args\u001b[38;5;241m=\u001b[39moptimizer_args)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m     scale_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_scale\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, closure)\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/cuda/amp/grad_scaler.py:414\u001b[0m, in \u001b[0;36mGradScaler.get_scale\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;124;03mReturns a Python float containing the current scale, or 1.0 if scaling is disabled.\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \n\u001b[1;32m    410\u001b[0m \u001b[38;5;124;03m.. warning::\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;124;03m    :meth:`get_scale` incurs a CPU-GPU sync.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enabled:\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_scale_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_batches = len(eval_dataloader)\n",
    "train_metrics = []\n",
    "val_metrics = []\n",
    "min_valid_metric = np.inf\n",
    "CONTINUE_TRAINING = False\n",
    "if CONTINUE_TRAINING:\n",
    "    saved_state_path = artifacts_dir + \"/20230112_UTAE_S2_B32_E20.pt\"\n",
    "    state_dict = torch.load(saved_state_path)\n",
    "    model.load_state_dict(state_dict)\n",
    "    # accelerator.load_state(artifacts_dir)\n",
    "    nb_epochs = 10\n",
    "else:\n",
    "    accelerator.save_state(artifacts_dir)\n",
    "\n",
    "for i in tqdm(range(nb_epochs)):\n",
    "    train_metrics_epoch = []\n",
    "    epoch_start = time()\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = batch[\"image\"]\n",
    "        targets = batch[\"target\"]\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        train_metrics_epoch.append(np.round(np.sqrt(loss.item()), 5))\n",
    "\n",
    "    epoch_end = time()\n",
    "    print(f\"Epoch training time: {epoch_end - epoch_start}\")\n",
    "    \n",
    "    # Save after each epoch\n",
    "    # Saving State Dict\n",
    "    torch.save(model.state_dict(), save_path[:-3] + \"_{i+1}.pt\")\n",
    "\n",
    "    accelerator.save_state(artifacts_dir)\n",
    "    \n",
    "    # Validation Loop\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(eval_dataloader):\n",
    "            inputs = batch[\"image\"]\n",
    "            targets = batch[\"target\"]\n",
    "            predictions = model(inputs)\n",
    "            # Gather all predictions and targets\n",
    "            all_predictions, all_targets = accelerator.gather_for_metrics((predictions, targets))\n",
    "            val_loss += loss_function(all_predictions, all_targets).item()\n",
    "\n",
    "    val_loss /= num_batches\n",
    "    val_rmse = np.round(np.sqrt(val_loss), 5)\n",
    "    print(f\"Validation Error: \\n RMSE: {val_rmse:>8f} \\n\")\n",
    "    train_metrics.extend(train_metrics_epoch)\n",
    "    val_metrics.append((len(train_metrics), val_rmse))\n",
    "    # check validation score, if improved then save model\n",
    "    if min_valid_metric > val_rmse:\n",
    "        print(f'Validation RMSE Decreased({min_valid_metric:.6f}--->{val_rmse:.6f}) \\t Saving The Model')\n",
    "        min_valid_metric = val_rmse\n",
    "\n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), save_path[:-3] + \"_BEST.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### Save the metrics to a file\n",
    "train_metrics_zipped = list(zip(np.arange(0, len(train_metrics)), train_metrics))\n",
    "metrics = {'training': train_metrics_zipped, 'validation': val_metrics}\n",
    "train_metrics_df = pd.DataFrame(metrics['training'], columns=[\"step\", \"score\"])\n",
    "val_metrics_df = pd.DataFrame(metrics[\"validation\"], columns=[\"step\", \"score\"])\n",
    "train_metrics_df.to_csv(artifacts_dir + \"/train_metrics.csv\")\n",
    "val_metrics_df.to_csv(artifacts_dir + \"/val_metrics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
