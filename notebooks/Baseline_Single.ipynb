{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f3f6333-379a-44cc-99dc-002087eb3868",
   "metadata": {},
   "source": [
    "# Train Baseline UNET model with Single Satellite Image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce072fa3-d560-4f50-acf5-6cd39a44aeda",
   "metadata": {},
   "source": [
    "!pip install --upgrade rasterio s3fs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e78446f-1221-432d-aa24-87bde670c042",
   "metadata": {},
   "source": [
    "# Install the local package\n",
    "!pip install -e /notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fce2ba2-67a9-4755-960b-bde2ae45ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e39f8b3-cfea-4b51-b412-31daf448f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb7f383b-3d3e-43c8-b976-4b221673cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from biomasstry.datasets import Sentinel2\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd1e69a0-0505-47f5-9d31-f54873e5593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen2dataset = Sentinel2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "474e3d9d-9f10-4b3a-b7c7-a16e6cc37208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "330d2718-3d23-442f-a5ac-4aafec0b61ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 6951 Val. samples: 1738\n"
     ]
    }
   ],
   "source": [
    "# split\n",
    "torch.manual_seed(0)\n",
    "train_frac = 0.8\n",
    "train_samples = round(train_frac * len(sen2dataset))\n",
    "val_samples = round((1 - train_frac) * len(sen2dataset))\n",
    "\n",
    "train_dataset, val_dataset = random_split(sen2dataset, [train_samples, val_samples])\n",
    "print(f\"Train samples: {len(train_dataset)} \"\n",
    "      f\"Val. samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcfa926c-e19b-4a98-a02d-8aa93a8cac5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# input channels: 10\n",
      "Image shape: torch.Size([10, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "img_data = train_dataset[0]['image']\n",
    "in_channels = img_data.shape[0]\n",
    "print(f'# input channels: {in_channels}')\n",
    "print(f\"Image shape: {img_data.shape}\")\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet50\",\n",
    "    encoder_weights=None, # 'imagenet' weights don't seem to help so start clean \n",
    "    in_channels=in_channels,                 \n",
    "    classes=1,                     \n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e887c76-2c8e-4818-bee9-7b95853ff1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "loss_module = nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38fd2c67-8fed-4eeb-aa9a-30560fd1b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Validation Loops\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    train_metrics = []\n",
    "    \n",
    "    print('Training')\n",
    "    for ix, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        X = batch['image'].to(device)\n",
    "        y = batch['target'].to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_metrics.append(np.round(np.sqrt(loss.item()), 5))\n",
    "            \n",
    "    return train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ccfa2e9-7ada-4e85-8993-de8e01fc858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_loop(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    valid_loss = 0\n",
    "    valid_metrics = {}\n",
    "\n",
    "    print('Validation')\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=num_batches):\n",
    "            X = batch['image'].to(device)\n",
    "            y = batch['target'].to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "            valid_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "    valid_loss /= num_batches\n",
    "    valid_rmse = np.round(np.sqrt(valid_loss), 5)\n",
    "    print(f\"Validation Error: \\n RMSE: {valid_rmse:>8f} \\n\")\n",
    "    return valid_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9049085-aefc-495d-88d9-18e70b8feb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, loss_module, optimizer, train_dataloader, val_dataloader, save_path, n_epochs=10):\n",
    "    min_valid_metric = np.inf\n",
    "    train_metrics = []\n",
    "    valid_metrics = []\n",
    "\n",
    "    for ix in range(n_epochs):\n",
    "        print(f\"\\n-------------------------------\\nEpoch {ix+1}\")\n",
    "        train_metrics_epoch = train_loop(train_dataloader, model, loss_module, optimizer)\n",
    "        train_metrics.extend(train_metrics_epoch)\n",
    "        \n",
    "        valid_metrics_epoch = valid_loop(val_dataloader, model, loss_module)\n",
    "        valid_metrics.append((len(train_metrics), valid_metrics_epoch))\n",
    "\n",
    "        # check validation score, if improved then save model\n",
    "        if min_valid_metric > valid_metrics_epoch:\n",
    "            print(f'Validation RMSE Decreased({min_valid_metric:.6f}--->{valid_metrics_epoch:.6f}) \\t Saving The Model')\n",
    "            min_valid_metric = valid_metrics_epoch\n",
    "\n",
    "            # Saving State Dict\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "    print(\"Done!\")\n",
    "    train_metrics_zipped = list(zip(np.arange(0, len(train_metrics)), train_metrics))\n",
    "    \n",
    "    return {'training': train_metrics_zipped, 'validation': valid_metrics}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8ed6718",
   "metadata": {},
   "source": [
    "## Experiment with `num_workers` and `batch_size` for tuning `DataLoader` Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a65948e-fac1-436f-96eb-54fb02cd3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "# num_workers = 4\n",
    "# batch_size = 64  # Note: training speed is sensitive to memory usage\n",
    "                 # set this as high as you can without significantly slowing down training time \n",
    "\n",
    "dir_saved_models = \"../artifacts\"\n",
    "# Expt. with num_workers and batch_size\n",
    "timing = []\n",
    "for num_workers in [2, 4, 6]:\n",
    "    for batch_size in [64, 128, 256]:\n",
    "        train_dataloader = DataLoader(train_dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=True,\n",
    "                                    num_workers=num_workers,\n",
    "                                    pin_memory=True\n",
    "                                    )\n",
    "\n",
    "        val_dataloader = DataLoader(val_dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=False,\n",
    "                                    num_workers=num_workers,\n",
    "                                    pin_memory=True\n",
    "                                )\n",
    "\n",
    "        save_file = f\"UNET_resnet50_10bandS2Apr_batch_AGBMLinear_1epoch_08DEC.pt\"\n",
    "        save_path = os.path.join(dir_saved_models, save_file)\n",
    "        # Kickoff training\n",
    "        n_epochs = 1\n",
    "        start = time()\n",
    "        metrics = run_training(model=model,\n",
    "                            loss_module=loss_module,\n",
    "                            optimizer=optimizer,\n",
    "                            train_dataloader=train_dataloader,\n",
    "                            val_dataloader=val_dataloader,\n",
    "                            save_path=save_path,\n",
    "                            n_epochs=n_epochs)\n",
    "        epoch_time = time() - start\n",
    "        timing.append((num_workers, batch_size, epoch_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeaa670",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Workers  Batch  Time\")\n",
    "for t in timing:\n",
    "    print(f\"{t[0]}       {t[1]}       {t[2]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
