{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f3f6333-379a-44cc-99dc-002087eb3868",
   "metadata": {},
   "source": [
    "# Train Baseline UNET model with Single Satellite Image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce072fa3-d560-4f50-acf5-6cd39a44aeda",
   "metadata": {},
   "source": [
    "!pip install --upgrade rasterio s3fs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e78446f-1221-432d-aa24-87bde670c042",
   "metadata": {},
   "source": [
    "# Install the local package\n",
    "!pip install -e /notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e39f8b3-cfea-4b51-b412-31daf448f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb7f383b-3d3e-43c8-b976-4b221673cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "062e5de4-62fc-47be-86a4-06b8f6ab1c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fce2ba2-67a9-4755-960b-bde2ae45ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45ab6120-6b84-489b-9316-2f4d028f0342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from biomasstry.datasets import Sentinel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "474e3d9d-9f10-4b3a-b7c7-a16e6cc37208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcfa926c-e19b-4a98-a02d-8aa93a8cac5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# input channels: 10\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "# img_data = train_dataset[0]['image']\n",
    "# in_channels = img_data.shape[0]\n",
    "in_channels = 10\n",
    "print(f'# input channels: {in_channels}')\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet50\",\n",
    "    encoder_weights=None, # 'imagenet' weights don't seem to help so start clean \n",
    "    in_channels=in_channels,                 \n",
    "    classes=1,                     \n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e887c76-2c8e-4818-bee9-7b95853ff1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "loss_module = nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38fd2c67-8fed-4eeb-aa9a-30560fd1b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Validation Loops\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    train_metrics = []\n",
    "    \n",
    "    print('Training')\n",
    "    for ix, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        X = batch['image'].to(device)\n",
    "        y = batch['target'].to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_metrics.append(np.round(np.sqrt(loss.item()), 5))\n",
    "            \n",
    "    return train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ccfa2e9-7ada-4e85-8993-de8e01fc858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_loop(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    valid_loss = 0\n",
    "    valid_metrics = {}\n",
    "\n",
    "    print('Validation')\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=num_batches):\n",
    "            X = batch['image'].to(device)\n",
    "            y = batch['target'].to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "            valid_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "    valid_loss /= num_batches\n",
    "    valid_rmse = np.round(np.sqrt(valid_loss), 5)\n",
    "    print(f\"Validation Error: \\n RMSE: {valid_rmse:>8f} \\n\")\n",
    "    return valid_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9049085-aefc-495d-88d9-18e70b8feb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, loss_module, optimizer, train_dataloader, val_dataloader, save_path, n_epochs=10):\n",
    "    min_valid_metric = np.inf\n",
    "    train_metrics = []\n",
    "    valid_metrics = []\n",
    "    \n",
    "    total_train_time = 0\n",
    "    total_val_time = 0\n",
    "\n",
    "    for ix in range(n_epochs):\n",
    "        print(f\"\\n-------------------------------\\nEpoch {ix+1}\")\n",
    "        start = time()\n",
    "        train_metrics_epoch = train_loop(train_dataloader, model, loss_module, optimizer)\n",
    "        end = time()\n",
    "        train_time = end - start\n",
    "        total_train_time += train_time\n",
    "        train_metrics.extend(train_metrics_epoch)\n",
    "        \n",
    "        start = time()\n",
    "        valid_metrics_epoch = valid_loop(val_dataloader, model, loss_module)\n",
    "        end = time()\n",
    "        val_time = end - start\n",
    "        total_val_time += val_time\n",
    "        valid_metrics.append((len(train_metrics), valid_metrics_epoch))\n",
    "\n",
    "        # check validation score, if improved then save model\n",
    "        if min_valid_metric > valid_metrics_epoch:\n",
    "            print(f'Validation RMSE Decreased({min_valid_metric:.6f}--->{valid_metrics_epoch:.6f}) \\t Saving The Model')\n",
    "            min_valid_metric = valid_metrics_epoch\n",
    "\n",
    "            # Saving State Dict\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "        print(f\"Train time: {train_time}. Validation time: {val_time}\")\n",
    "    print(\"Done!\")\n",
    "    print(f\"Total train time: {total_train_time} s. Avg. time per epoch: {total_train_time / n_epochs}\")\n",
    "    print(f\"Total val time: {total_val_time} s. Avg. time per epoch: {total_val_time / n_epochs}\")\n",
    "    train_metrics_zipped = list(zip(np.arange(0, len(train_metrics)), train_metrics))\n",
    "    \n",
    "    return {'training': train_metrics_zipped, 'validation': valid_metrics}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ed6718",
   "metadata": {},
   "source": [
    "## Experiment with `num_workers` and `batch_size` for tuning `DataLoader` Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13170fe1-3657-499c-be13-e90ac1b599d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 6951 Val. samples: 1738\n",
      "\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606459fc512a485397db5502052535b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataset.py\", line 290, in __getitem__\n    return self.dataset[self.indices[idx]]\n  File \"/notebooks/src/biomasstry/datasets/sentinel2.py\", line 157, in __getitem__\n    img_data = load_raster(img_path)[:10]  # only first 10 channels, leave out cloud coverage channel\n  File \"/notebooks/src/biomasstry/datasets/sentinel2.py\", line 31, in load_raster\n    with fsspec.open(file_url, **storage_options).open() as f:\n  File \"/usr/local/lib/python3.9/dist-packages/fsspec/core.py\", line 135, in open\n    return self.__enter__()\n  File \"/usr/local/lib/python3.9/dist-packages/fsspec/core.py\", line 103, in __enter__\n    f = self.fs.open(self.path, mode=mode)\n  File \"/usr/local/lib/python3.9/dist-packages/fsspec/spec.py\", line 1106, in open\n    f = self._open(\n  File \"/usr/local/lib/python3.9/dist-packages/fsspec/implementations/local.py\", line 175, in _open\n    return LocalFileOpener(path, mode, fs=self, **kwargs)\n  File \"/usr/local/lib/python3.9/dist-packages/fsspec/implementations/local.py\", line 273, in __init__\n    self._open()\n  File \"/usr/local/lib/python3.9/dist-packages/fsspec/implementations/local.py\", line 278, in _open\n    self.f = open(self.path, mode=self.mode)\nFileNotFoundError: [Errno 2] No such file or directory: '/datasets/biomassters/train_features/d81e03d4_S2_00.tif'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_saved_models, save_file)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Kickoff training\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mloss_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Save the metrics to a file\u001b[39;00m\n\u001b[1;32m     48\u001b[0m train_metrics_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m], columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(model, loss_module, optimizer, train_dataloader, val_dataloader, save_path, n_epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mix\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 12\u001b[0m train_metrics_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m end \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     14\u001b[0m train_time \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      3\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ix, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(dataloader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader)):\n\u001b[1;32m      7\u001b[0m     X \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m     y \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tqdm/notebook.py:258\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:1347\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:1373\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1373\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_utils.py:461\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 461\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataset.py\", line 290, in __getitem__\n    return self.dataset[self.indices[idx]]\n  File \"/notebooks/src/biomasstry/datasets/sentinel2.py\", line 157, in __getitem__\n    img_data = load_raster(img_path)[:10]  # only first 10 channels, leave out cloud coverage channel\n  File \"/notebooks/src/biomasstry/datasets/sentinel2.py\", line 31, in load_raster\n    with fsspec.open(file_url, **storage_options).open() as f:\n  File \"/usr/local/lib/python3.9/dist-packages/fsspec/core.py\", line 135, in open\n    return self.__enter__()\n  File \"/usr/local/lib/python3.9/dist-packages/fsspec/core.py\", line 103, in __enter__\n    f = self.fs.open(self.path, mode=mode)\n  File \"/usr/local/lib/python3.9/dist-packages/fsspec/spec.py\", line 1106, in open\n    f = self._open(\n  File \"/usr/local/lib/python3.9/dist-packages/fsspec/implementations/local.py\", line 175, in _open\n    return LocalFileOpener(path, mode, fs=self, **kwargs)\n  File \"/usr/local/lib/python3.9/dist-packages/fsspec/implementations/local.py\", line 273, in __init__\n    self._open()\n  File \"/usr/local/lib/python3.9/dist-packages/fsspec/implementations/local.py\", line 278, in _open\n    self.f = open(self.path, mode=self.mode)\nFileNotFoundError: [Errno 2] No such file or directory: '/datasets/biomassters/train_features/d81e03d4_S2_00.tif'\n"
     ]
    }
   ],
   "source": [
    "# Train a model for each of the months below\n",
    "months = [\"september\", \"october\"]\n",
    "train_frac = 0.8\n",
    "\n",
    "torch.manual_seed(0)\n",
    "dir_saved_models = \"/notebooks/artifacts\"\n",
    "num_workers = 6\n",
    "batch_size = 32  # Note: training speed is sensitive to memory usage\n",
    "                 # set this as high as you can without significantly slowing down training time \n",
    "n_epochs = 25\n",
    "for month in months:\n",
    "    sen2dataset = Sentinel2(month=month)\n",
    "    \n",
    "    # split\n",
    "    train_samples = round(train_frac * len(sen2dataset))\n",
    "    val_samples = round((1 - train_frac) * len(sen2dataset))\n",
    "    train_dataset, val_dataset = random_split(sen2dataset, [train_samples, val_samples])\n",
    "    print(f\"Train samples: {len(train_dataset)} \"\n",
    "          f\"Val. samples: {len(val_dataset)}\")\n",
    "\n",
    "    # DataLoaders\n",
    "    train_dataloader = DataLoader(train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True,\n",
    "                                num_workers=num_workers,\n",
    "                                pin_memory=True\n",
    "                                )\n",
    "\n",
    "    val_dataloader = DataLoader(val_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                num_workers=num_workers,\n",
    "                                pin_memory=True\n",
    "                            )\n",
    "\n",
    "    save_file = f\"UNET_resnet50_10bandS2{month}_batch64_AGBMLinear_20epoch_10DEC.pt\"\n",
    "    save_path = os.path.join(dir_saved_models, save_file)\n",
    "    # Kickoff training\n",
    "\n",
    "    metrics = run_training(model=model,\n",
    "                        loss_module=loss_module,\n",
    "                        optimizer=optimizer,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=val_dataloader,\n",
    "                        save_path=save_path,\n",
    "                        n_epochs=n_epochs)\n",
    "    # Save the metrics to a file\n",
    "    train_metrics_df = pd.DataFrame(metrics['training'], columns=[\"step\", \"score\"])\n",
    "    val_metrics_df = pd.DataFrame(metrics[\"validation\"], columns=[\"step\", \"score\"])\n",
    "    train_metrics_df.to_csv(dir_saved_models + f\"/unet_s2_{month}_train_metrics.csv\")\n",
    "    val_metrics_df.to_csv(dir_saved_models + f\"/unet_s2_{month}_val_metrics.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
