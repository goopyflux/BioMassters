{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cae1cf7-f455-4845-a1ed-5d2a7d28b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f485233e-da45-4679-9a9a-9b9cc641e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file = \"/notebooks/data/metadata_parquet/features_metadata_slim.parquet\"\n",
    "metadata_df = pd.read_parquet(metadata_file)\n",
    "chip_ids = metadata_df[metadata_df.split == \"train\"].chip_id.unique().astype(np.str_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bc1a79d-46e3-4daa-9564-498ed3f5cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chip_lst = chip_ids.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab0f9880-6b77-480a-b106-7142102891da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpySerializedList():\n",
    "    def __init__(self, lst: list):\n",
    "        def _serialize(data):\n",
    "            buffer = pickle.dumps(data, protocol=-1)\n",
    "            return np.frombuffer(buffer, dtype=np.uint8)\n",
    "\n",
    "        print(\n",
    "            \"Serializing {} elements to byte tensors and concatenating them all ...\".format(\n",
    "                len(lst)\n",
    "            )\n",
    "        )\n",
    "        self._lst = [_serialize(x) for x in lst]\n",
    "        self._addr = np.asarray([len(x) for x in self._lst], dtype=np.int64)\n",
    "        self._addr = np.cumsum(self._addr)\n",
    "        self._lst = np.concatenate(self._lst)\n",
    "        print(\"Serialized dataset takes {:.2f} MiB\".format(len(self._lst) / 1024**2))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._addr)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_addr = 0 if idx == 0 else self._addr[idx - 1].item()\n",
    "        end_addr = self._addr[idx].item()\n",
    "        bytes = memoryview(self._lst[start_addr:end_addr])\n",
    "        return pickle.loads(bytes)\n",
    "\n",
    "\n",
    "class TorchSerializedList(NumpySerializedList):\n",
    "    def __init__(self, lst: list):\n",
    "        super().__init__(lst)\n",
    "        self._addr = torch.from_numpy(self._addr)\n",
    "        self._lst = torch.from_numpy(self._lst)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_addr = 0 if idx == 0 else self._addr[idx - 1].item()\n",
    "        end_addr = self._addr[idx].item()\n",
    "        bytes = memoryview(self._lst[start_addr:end_addr].numpy())\n",
    "        return pickle.loads(bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0adfdb0c-7054-4fd7-8ff1-21c4727cc49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serializing 8689 elements to byte tensors and concatenating them all ...\n",
      "Serialized dataset takes 0.19 MiB\n"
     ]
    }
   ],
   "source": [
    "ts_lst = TorchSerializedList(chip_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e1c6aa6-fe0a-4eee-8e3b-2cba255cc8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0003d2eb\n"
     ]
    }
   ],
   "source": [
    "print(ts_lst[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
